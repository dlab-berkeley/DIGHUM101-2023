{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>DIGHUM101</b></center>\n",
    "<center>1-9: Pandas</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast review\n",
    "\n",
    "1. What is a list?\n",
    "2. What is a dictionary? \n",
    "3. What is a Pytyon library? \n",
    "4. What are two conventions for importing data from files in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning objectives\n",
    "\n",
    "0. Review .csv importation, the working directory, and two common errors: Name and File\n",
    "1. Begin to work with data frames in Python (tabular structures, like a spreadsheet!) \n",
    "2. Basic methods: `.head()`, `.rename()`, `.describe()`, and `.value_counts()`\n",
    "3. Basic attributes: `.columns` and `.shape`\n",
    "4. Subsetting: `.iloc()`, `.loc()`, and conditional \n",
    "5. Adding and removing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is designed to make it easier to work with [structured data](https://learn.g2.com/structured-vs-unstructured-data). Most of the analyses you might perform will likely involve using tabular data, e.g., from .csv files or relational databases (e.g., SQL). The DataFrame object in pandas is \"a two-dimensional tabular, column-oriented data structure with both row and column labels.\"\n",
    "\n",
    "**i.e., a spreadsheet!**\n",
    "\n",
    "The pandas name itself is derived from panel data, an econometrics term for multidimensional structured data sets, and Python data analysis itself. [Check out the Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/) to learn more! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import .csv file\n",
    "\n",
    "Import the correspondence dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uh-oh! # What is a NameError? Review \"1-8_errors-help.ipynb\" for a hint.\n",
    "letters = pd.read_csv(\"correspondence-data-1585.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Now we are good to go, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a FileError? Review \"1-8_errors-help.ipynb\" for a hint.\n",
    "letters = pd.read_csv(\"correspondence-data-1585.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the working directory\n",
    "\n",
    "Remember to...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, view the file path to your current working directory:\n",
    "# %pwd\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then change the working directory path to the Data folder\n",
    "# Go \"up\" two levels in your file structure and into the Data folder:\n",
    "os.chdir(\"../../Data/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the files in the working directory\n",
    "# You should see \"correspondence-data-1585.csv\"\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the file! :) \n",
    "letters = pd.read_csv(\"correspondence-data-1585.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.head()`, `.describe()`, and `.value_counts()`\n",
    "\n",
    "The `.head()` method will show the first five rows by default. Put an integer in the parentheses to specify a different number of rows. \n",
    "\n",
    "`.describe()` provides basic summary statistics. \n",
    "\n",
    "`.value_counts()` counts frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 3 rows\n",
    "letters.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce some quick summary statistics\n",
    "letters.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.value_counts()`\n",
    "\n",
    "Now, we can investigate how many of each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many letters by each writer?\n",
    "letters[\"writer\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which city was the most frequent source?\n",
    "letters[\"source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which city was the most frequent destination?\n",
    "letters[\"destination\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column names\n",
    "\n",
    "You can call [attributes](https://medium.com/@shawnnkoski/pandas-attributes-867a169e6d9b) of a Pandas variable by using \"dot notation\" - but without the parentheses to unpack more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error! No such method exists\n",
    "letters.columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions or methods are callable objects while data types are not\n",
    "callable(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the column names using the .columns *attribute*\n",
    "letters.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Columns\n",
    "\n",
    "Select a single column by typing its name as a string in square brackets. View just the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters[\"writer\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double lists\n",
    "\n",
    "You can also call multiple columns by passing their names in as strings to a [double list](https://stackoverflow.com/questions/33417991/pandas-why-are-double-brackets-needed-to-select-column-after-boolean-indexing)! View just the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's a lot of square brackets!\n",
    "letters[[\"writer\", \"date\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.rename()`\n",
    "\n",
    "Nice! Now that we know how to access the column names, we can edit the columns names with the .`rename()` method.\n",
    "\n",
    "Pass in a dictionary argument to the columns parameter like this: `columns = {\"old_name\":\"new_name\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.rename(columns = {\"writer\" : \"Writer\", \n",
    "                          \"source\" : \"Origin\",\n",
    "                          \"destination\" : \"Dest\",\n",
    "                          \"date\" : \"Date\"}, \n",
    "               inplace = True) # what does inplace = True mean? How do you find out?\n",
    "\n",
    "# View the updated column names\n",
    "print(letters.columns)\n",
    "\n",
    "# or\n",
    "\n",
    "letters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice Rows\n",
    "\n",
    "You can slice rows like you would a string or a list. If we just want three rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters[6:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.iloc()`\n",
    "\n",
    "... or use `.iloc()` to return non-consecutive rows. Pass in **integers** as a double list. \n",
    "\n",
    "For example, to get the 4th, 12th, and 29th rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.iloc[[3, 11, 28]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and pass in a second interior list to specify columns! Select just the \"Writer\" (0th index) and \"Date\" (3rd index) columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.iloc[[3, 11, 28], [0,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.loc()` \n",
    "\n",
    "While `.iloc()` requires integers, regular `.loc()` allows you to pass in column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.loc[[3, 11, 28], [\"Writer\", \"Date\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Subsetting\n",
    "\n",
    "What is we want a subset based on a condition? For example, what if we just wanted a subset for data only when Destination is equal to Haarlem? \n",
    "\n",
    "... _and_ Writer is equal to Meulen, Andries van der?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters[\"Dest\"] == \"Haarlem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame just of Haarlem destinations...\n",
    "h = letters.loc[letters[\"Dest\"] != \"Haarlem\"]\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame just of Andries van der Meulen\n",
    "am = letters.loc[letters[\"Writer\"] == \"Meulen, Andries van der\"]\n",
    "am.head()\n",
    "\n",
    "# What does the .shape attribute do?\n",
    "# 63 rows and 4 columns\n",
    "am.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4 > 3) and (4 < 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data frame that includes both Haarlem as the destination AND Andries van der Meulen \n",
    "both = letters.loc[(letters[\"Dest\"] == \"Haarlem\") |\n",
    "                   (letters[\"Writer\"] == \"Meulen, Andries van der\")]\n",
    "both.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more by [reading the documentation here](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html) - what is the difference between `&` and `|` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort Values\n",
    "Sorting values can be valuable when we need to, well, sort the values of a (part of a) DataFrame! For instance, we can get only the letters with a destination of Delft, then sort the values in ascending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters[letters[\"Dest\"] == \"Delft\"].sort_values(\"Date\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Groupby()`\n",
    "\n",
    "The `groupby()` method allows you to split your data into separate groups to perform computations such as `min()`, `mean()`, `sum()`, and so on. For instance, we can group by destination, then get the `describe()` valuse of each column. Try to see if you understand what this does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.groupby(\"Dest\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Column\n",
    "\n",
    "You can add a new column by renaming it in place - just like with a list or dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "letters[\"Estimated_Arrival\"] = \"Arrival date\"\n",
    "\n",
    "# All entries for \"Estimated_Arrival\" say \"Arrival date\"\n",
    "letters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced: working with datetimes\n",
    "We can populate this column with the results of some expression/calculation. Perhaps we estimated it would have taken 10 days for a letter to reach its destination.\n",
    "\n",
    "> NOTE: Working with datetimes in Python can be particularly frustrating! You will learn more about custom functions, for loops, list comprehensions, and lambda functions starting in week 3. The reason we are glossing over them now is so that you focus on what is possible for planning your individual projects instead of getting lost and frustrated in the nuances of the Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datetimes are a Pandas object that allow us to work with - you guessed it - dates. Let's try to convert this column to a datetime using Pandas' `to_datetime()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(letters['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that doesn't work. Here's why:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp.min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out the timespan that can be represented using a 64-bit integer is limited to approximately 584 years. So we have to find a workaround. We apply a `lambda` (anonymous) function to the Date column, turning it into a `Period` object (read more [here](https://pandas.pydata.org/docs/reference/api/pandas.Period.html) if you are so inclined). \n",
    "\n",
    "Again: don't worry about the details of the following code cells. This is just to show you that sometimes, you have to find workarounds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters['Date'] = letters['Date'].apply(lambda x: pd.Period(x, freq='D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `dtype` for this column has changed to `Period`. This means we can now perform datetime-like operations on it. Let's write a function that takes a datetime in, adds 10 days to it using the [`timedelta`](https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html) method, and returns the datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDays(dt):\n",
    "    fulldate = datetime(dt.year, dt.month, dt.day)\n",
    "    fulldate = fulldate + timedelta(days=10)\n",
    "    return fulldate.date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then again `apply` a function to this column, this time the function we just created, and throw the output into a new column called \"Estimated_arrival\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters['Estimated_Arrival'] = letters['Date'].apply(addDays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My first visualization\n",
    "\n",
    "We'll get into this in the weeks to come, but here's a sneak peak on how to make a quick visualization using the seaborn library. We're plotting the letters' destinations on the X-axis and change hues for the letters' origin. Turns out a lof of them come from Antwerp!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(              \n",
    "    data=letters,         \n",
    "    x=\"Dest\",\n",
    "    hue=\"Origin\", \n",
    "    multiple=\"fill\"\n",
    ")\n",
    "\n",
    "# try changing the \"multiple\" parameter to any of “layer”, “dodge”, “stack”, “fill”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Column\n",
    "\n",
    "Finally, we can use our `del` statement to delete a column just like we did with lists: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Date\" is removed!\n",
    "del letters[\"Date\"]\n",
    "letters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
