{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math and stats libraries\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic machine learning workflow\n",
    "\n",
    "Refer back to **4-2_Machine-Learning-Review.pdf** to review your key terms. Below is a simplified workflow:\n",
    "\n",
    "1. Do you want to predict something? \n",
    "    - Yes = supervised learning (y ~ X)\n",
    "    - No = unsupervised learning (~ X)\n",
    "2. If supervised:\n",
    "    - Syntax looks like this: **y ~ X** ([use x to predict y](https://stats.stackexchange.com/questions/207425/why-do-we-say-the-outcome-variable-is-regressed-on-the-predictors)), or \"regress y on X\".\n",
    "    - **y** is the thing we want to predict! (dependent/target/outcome variable)\n",
    "    - **x** is the thing(s) we use to do the predicting (independent/predictor/input variable)\n",
    "3. If supervised:\n",
    "    - perform **regression** if the **y** variable is continuous\n",
    "    - perform **classification** if the **y** variable is discrete/categorical\n",
    "4. If unsupervised: \n",
    "    - Syntax looks like this: **~ X**\n",
    "    - We only have **X** variables, and we want to see how they sort on their own accord without trying to predict anything.\n",
    "5. Handle missing data\n",
    "    - Missing data should be handled somehow. [Listwise deletion](https://en.wikipedia.org/wiki/Listwise_deletion) is common but not preferred because of the amount of information that is lost. [Mean imputation](https://en.wikipedia.org/wiki/Imputation_(statistics)#Mean_substitution) is also used but is sensitive to outliers. [Median imputation](https://stats.stackexchange.com/questions/143700/which-is-better-replacement-by-mean-and-replacement-by-median) is often reliable and interpretable. [Generalized low rank models](https://web.stanford.edu/~boyd/papers/pdf/glrm.pdf) are preferred! \n",
    "6. Convert categorical variables to indicators\n",
    "    - Use [one-hot encoding](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f) to your advantage! Most supervised algorithms handle factor/categorical data poorly (decision trees being a main exception). \n",
    "7. Split the data\n",
    "    - [Split the original dataset](https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets) so that (arbitrarily) 70% is assigned to the **training set** and the remaining 30% to the **test set**. \n",
    "        - Use [random sampling]() if you are splitting continuous data. \n",
    "        - Use [stratified](https://en.wikipedia.org/wiki/Stratified_sampling) [sampling](https://www.investopedia.com/ask/answers/032615/what-are-some-examples-stratified-random-sampling.asp#:~:text=Stratified%20random%20sampling%20divides%20a,of%20the%20groups%20or%20strata.&text=Stratified%20random%20sampling%20is%20a%20method%20of%20sampling%2C%20which%20is,a%20sample%20size%20for%20study.) if you are splitting categorical data. \n",
    "    - [Data splitting](https://www.mff.cuni.cz/veda/konference/wds/proc/pdf10/WDS10_105_i1_Reitermanova.pdf) is a fundamental preprocessing step! \n",
    "    - [Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) is even better because it repeats this splitting _k_ number of times.\n",
    "8. Fit the model to the training set and evaluate its performance. \n",
    "    - Fit the data to the training set so it can \"learn\" the relationships between the **X and y** variables. \n",
    "    - Then use a [performance](https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce) [metric](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers) to see how well the model fit the data. \n",
    "    - What is a [loss](https://en.wikipedia.org/wiki/Loss_functions_for_classification) [function](https://medium.com/@phuctrt/loss-functions-why-what-where-or-when-189815343d3f)?\n",
    "    - The model is **underfit** if the model performs poorly on the training dataset. \n",
    "9. Fit the data to the test set and evaluate its performance\n",
    "    - See how well the model performs on the test set; hopefully we see roughly similar performances for the training and test sets. \n",
    "    - The model is **overfit** if the model performs well on the training dataset but poorly on the test dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The value of understanding simple linear regression\n",
    "\n",
    "Doing a simple [OLS](https://en.wikipedia.org/wiki/Ordinary_least_squares) regression step-by-step provides a way to understand the supervised machine learning process. \n",
    "\n",
    "> NOTE: Remember to [learn the assumptions of linear or logistic regression (or any other statistical test)](https://www.lexjansen.com/wuss/2018/130_Final_Paper_PDF.pdf) before using it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate some data\n",
    "\n",
    "First, let's generate toy predictor X and response y variables and compute their means. This will be our \"training set\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate toy predictor (x) and response (y) variables\n",
    "X = np.array([1, 1.5, 4, 7])\n",
    "y = np.array([4, 3, 8.2, 9])\n",
    "\n",
    "# Convert to data frame\n",
    "df = pd.DataFrame({\"X\": X,\n",
    "                   \"y\": y})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate means of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_X = round(sum(df.X) / len(df.X), 2)\n",
    "mean_y = round(sum(df.y) / len(df.y), 2)\n",
    "print(\"mean of x is:\", mean_X)\n",
    "print(\"mean of y is:\", mean_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym = [np.mean(y) for i in X]\n",
    "xm = [np.mean(X) for i in y]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set(xlim=(0,8))\n",
    "\n",
    "sns.scatterplot(data=df, x='X', y='y')\n",
    "sns.lineplot(x=X, y= ym, linestyle='--')\n",
    "sns.lineplot(x=xm, y= y, linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate the error for each observation\n",
    "\n",
    "Numpy allows us to perform \"vectorized\" operations, such as subtracting the mean of `X` from each `X` value or the mean of `y` from each `y` value. That is, we can do math on arrays of numbers simultaneously: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Point errors for x is:\", X - mean_X)\n",
    "print(\"Point errors for y is:\", y - mean_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate the beta coefficients\n",
    "\n",
    "Remember we're trying to find the equation for the *line of best fit*, which minimizes the sum of the squared errors (the vertical distances between each point and the regression line). This line has a few properties:\n",
    "\n",
    "1. y_intercept (or B0 coefficient): where does the line intercept the y-axis?\n",
    "2. slope (or B1 coeficcient): for each X, how much increase in y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimate the B1 coefficient (slope)\n",
    "B1 = sum((X - mean_X) * (y-mean_y)) / sum((X - mean_X) **2)\n",
    "print(\"slope (B1) is equal to\", round(B1, 5))\n",
    "\n",
    "## Estimate B0 coefficient (intercept)\n",
    "B0 = mean_y - (B1 * mean_X)\n",
    "print(\"intercept (B0) is equal to\", round(B0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT \n",
    "reg = B0 + B1*X\n",
    "\n",
    "sns.scatterplot(data=df, x='X', y='y')\n",
    "sns.lineplot(x=X, y= ym, linestyle='--')\n",
    "sns.lineplot(x=xm, y= y, linestyle='--')\n",
    "sns.lineplot(x=X, y=reg, linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plot the best fit line\n",
    "\n",
    "Now we can do all of this work using the `regplot()` function from Seaborn - read more about it [here](https://seaborn.pydata.org/generated/seaborn.regplot.html). Basically, we're skipping all of the calculations we just did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = sns.regplot(x = \"X\", y = \"y\", \n",
    "            data = df, \n",
    "            ci = None); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the plot starts at 1 at the x-axis so we don't actually see the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Generate predicted values\n",
    "\n",
    "Now that we have calculated the best fit line, we can generate predicted values and assess the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predicted y values by plugging our x values into the equation\n",
    "y_hat = B0 + (B1 * X)\n",
    "\n",
    "pd.DataFrame({\"y\": y, \"predicted y\": y_hat})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Evaluate performance\n",
    "\n",
    "Our performance metric will be [root mean square error (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation), or the standard deviation of the residuals (aka prediction errors). Error is measured as the vertical distance from a data point to the best fit line. \n",
    "\n",
    "However, we have to do some calculations first before we get to RMSE! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, calculate the error for each observation by subracting the predicted value from it:\n",
    "y_error = y - y_hat\n",
    "print(y_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, calculate the square of each of these errors \n",
    "# (we do this to treat positive and negative discrepancies in the same way):\n",
    "y_error_sq = y_error ** 2\n",
    "print(y_error_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third, sum these values\n",
    "sum_squared_error = sum(y_error_sq)\n",
    "print(sum_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fourth, calculate the RMSE - take the square root of the summed squared error divided by the length of y:\n",
    "RMSE = math.sqrt(sum_squared_error / len(y))\n",
    "print(round(RMSE, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our RMSE gives us a measure of difference between our predicted values and the actual values. An RMSE of 0 (almost never achieved in practice) would indicate a perfect fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. How did we do? \n",
    "\n",
    "Compare the slope and intercept from `stats.linregress` to our estimations by hand (under step 5). Are they the same? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_mod = stats.linregress(X, y)\n",
    "print(\"intercept is\", lin_mod.intercept)\n",
    "print(\"slope is\", lin_mod.slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate RMSE from the `sklearn.metrics.mean_squared_error` function to compare to our estimations by hand. How did we do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the squared=false parameter as we took the square root\n",
    "\n",
    "metrics.mean_squared_error(y, y_hat, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "[Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) provides a useful way to classify text. It is a process of modeling the probability of a discrete outcome given an input variable. The most common logistic regression models a binary outcome: something that can take two values such as true/false, yes/no, and so on.\n",
    "\n",
    "First, create some toy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = pd.DataFrame({'Study_Hours' : [2.0, 6.9, 1.6, 9.8, 1.1, 5.8, 3.4, 8.5, 6.7, 1.6, 8.6, 3.4, 9.4, 5.6, 12.0, 3.2, 3.5, 6, 9.7, 6.5],\n",
    "                      'Grade' : [60.0, 83.6, 35.4, 79.2, 42.4, 98.2, 67.6, 84.0, 93.8, 64.4, 100.0, 61.6, 100.0, 69.4, 98.4, 41.8, 72.0, 59.0, 90.8, 100.0],\n",
    "                      'Pass' : [1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1]})\n",
    "study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data\n",
    "\n",
    "First, let's run a linear regression between hours studied and grade. We'll use the `LinearRegression` method from `sklearn` as well this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that LinearRegression() expects 2-D data of shape [n_samples, n_features] for x value\n",
    "\n",
    "X = study.drop(columns=[\"Pass\", \"Study_Hours\"])\n",
    "y = np.array(study.Grade)\n",
    "\n",
    "lin_r = LinearRegression()\n",
    "lin_r.fit(X,y)\n",
    "print(lin_r.coef_, lin_r.intercept_)\n",
    "\n",
    "# or with stats package\n",
    "print(stats.linregress(x = study.Study_Hours, y = study.Grade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here's the regression plot between study hours and grade\n",
    "sns.regplot(x = \"Study_Hours\", y = \"Grade\", \n",
    "            data = study, color = \"k\", ci=None,\n",
    "            line_kws={'color':'purple'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuiting the Logistic Regression Model\n",
    "\n",
    "But what happens if your **y** variable is categorical and not continuous? Suppose we don't care about the `Grade` score, but we just care if you pass the course or not?\n",
    "\n",
    "0 = no pass  \n",
    "1 = pass\n",
    "\n",
    "> NOTE: Recall that logistic regression can perform both regression and classification depending on the distribution of the y variable. For classification, we are interested in the _class probabilities_ of a 1 or a 0 at some threshold, for example: < 0.5 (for 0) and >= 0.5 (for 1). This is called *binary logistic regression*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we fit a line to that? That's where the [logistic function](https://en.wikipedia.org/wiki/Logistic_function) can be handy. The general logistic function is:\n",
    "\n",
    "$ f(x) = \\frac{1}{1 + e^{-x}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `LogisticRegression` function\n",
    "\n",
    "Let's go back to `sklearn` and save our logistic model in a variable named `lr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_r = LogisticRegression(random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = study.drop(columns=[\"Pass\", \"Grade\"])\n",
    "y = study[\"Pass\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `fit` function on our `X` and `y`. Recall that \"fitting a model\" is the process of specifying the model that provides the line of best fit for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_r.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly look at the `score` of our model, which we can interpret as its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_r.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out 85% of our data are correctly predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run the `regplot` from seaborn again (note this is running logistic regression all on its own)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = study.Study_Hours, y = study.Pass, \n",
    "            logistic = True, \n",
    "            color = \"k\",\n",
    "            line_kws={'color':'red'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split\n",
    "\n",
    "Well, let's see how the logistic regression performs on training and test set data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x and y variables for training and test sets. Split the data! \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    # Which dataset? \n",
    "    study, \n",
    "    \n",
    "    # What is the outcome variable?\n",
    "    study.Pass,\n",
    "    \n",
    "    # How much data should be assigned to the test set? \n",
    "    # 1 minus this number will be automatically assigned to the training set\n",
    "    test_size = 0.30, \n",
    "    \n",
    "    # Ensure we get the same train/test split each time\n",
    "    random_state = 40,\n",
    "\n",
    "    # Ensure that our y labels are balanced\n",
    "    stratify = y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default settings except for the solver!\n",
    "# https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions\n",
    "logistreg = LogisticRegression(solver = \"liblinear\")\n",
    "logistreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "logistreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification accuracy on the training set\n",
    "# Nice! \n",
    "logistreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predicted y values based on the x test set data\n",
    "predictions = logistreg.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification accuracy on the test set\n",
    "score = logistreg.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix: https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fancy it up! Use plt.savefig() to export\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot = True, fmt = \".0f\", \n",
    "            cbar = False, linewidths = 2, \n",
    "            square = True, cmap = 'YlGnBu', annot_kws={\"size\": 20})\n",
    "plt.ylabel('Actual y label')\n",
    "plt.xlabel('Predicted y label')\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other algorithms\n",
    "\n",
    "This is the gist! Download the [Machine Learning in Python](https://github.com/dlab-berkeley/python-machine-learning) materials to see how other algorithms work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
