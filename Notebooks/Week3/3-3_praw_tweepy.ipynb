{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>DIGHUM101</b></center>\n",
    "<center>3-3: PRAW and Tweepy (Reddit and Twitter APIs)</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Social Media Data\n",
    "\n",
    "Data from social media platforms are more important than ever. However, critical analysis and fact-checking are also more important than ever as misinformation, hatespeech, bots, and trolling become more and more prevalent. [Reddit](https://www.reddit.com/) and [Twitter](https://twitter.com/) are two of the most popular social media websites with useful public APIs.\n",
    "\n",
    "Note that [DIGHUM160](http://guide.berkeley.edu/courses/dighum/) consists of more extensive critical research on Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library installations\n",
    "\n",
    "#!pip install praw\n",
    "#!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "# Python Reddit API Wrapper\n",
    "import praw\n",
    "\n",
    "# Twitter API client\n",
    "import tweepy\n",
    "\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit\n",
    "\n",
    "Let's follow this tutorial to see how you can connect to Reddit's [API](https://en.wikipedia.org/wiki/Application_programming_interface): \n",
    "\n",
    "https://pythonprogramming.net/introduction-python-reddit-api-wrapper-praw-tutorial/\n",
    "\n",
    "[The praw documentation is also very useful](https://praw.readthedocs.io/en/latest/getting_started/quick_start.html)!\n",
    "\n",
    "1. Visit https://www.reddit.com/\n",
    "2. Click \"Sign Up/Log In\" to create an account or login\n",
    "3. Go to https://old.reddit.com/prefs/apps/\n",
    "4. Click \"Create an ap\" (at the bottom of the page)\n",
    "5. Click the \"script\" radio button (**not** a \"web app\" or \"installed app\"!)\n",
    "6. Give your project a name and description\n",
    "7. Enter an \"about URL\" if you choose (such as your project name)\n",
    "8. Enter http://localhost:8080 for your the \"redirect uri\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Authenticate!\n",
    "\n",
    "Create an instance and add your information: \n",
    "\n",
    "- client_id = the code under your project name in the upper-left\n",
    "- client_secret = your API access token\n",
    "- password = your password\n",
    "- user_agent = put something like: 'dhe 1.0 by /u/dh_example'\n",
    "- username = your username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![reddit](../../Img/reddit-API.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Reddit API instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need these 5 things - let's overwrite them with our own!\n",
    "\n",
    "reddit = praw.Reddit(client_id='YOUR_CLIENT_ID',\n",
    "                     client_secret='YOUR_CLIENT_SECRET',\n",
    "                     password='YOUR_REDDIT_PSW',\n",
    "                     user_agent='dh by /u/YOUR_USERNAME', \n",
    "                     username='YOUR_USERNAME'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out a subreddit\n",
    "subreddit = reddit.subreddit('BlackLivesMatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit.description_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the Python subreddit by top-scoring topics\n",
    "hot_blm = subreddit.top()\n",
    "hot_blm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out reddit methods\n",
    "#reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out subreddit methods - you can also get hot topics, controversial topics, etc.\n",
    "subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over the \"hot\" submissions to get the object IDs\n",
    "for submission in hot_blm:\n",
    "    print(submission.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return just the first 5 submissions and print their selftext\n",
    "hot_blm = subreddit.hot(limit = 5)\n",
    "for submission in hot_blm:\n",
    "    print(submission.selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a blank dictionary to store the metadata\n",
    "conversedict = {}\n",
    "\n",
    "# Get more information\n",
    "hot_blm = subreddit.top(limit = 5)\n",
    "for submission in hot_blm:\n",
    "    if not submission.stickied:\n",
    "        print('title: {}, created: {}, score: {}, ratio: {}'.format(submission.title,\n",
    "                                                                submission.created,\n",
    "                                                                submission.score,\n",
    "                                                                submission.upvote_ratio))\n",
    "        \n",
    "        submission.comments.replace_more(limit=0)\n",
    "        for comment in submission.comments.list():\n",
    "            if comment.id not in conversedict:\n",
    "                conversedict[comment.id] = [comment.body,{}]\n",
    "                if comment.parent() != submission.id:\n",
    "                    parent = str(comment.parent())\n",
    "                    conversedict[parent][1][comment.id] = [comment.ups, comment.body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a blank list for export to data frame\n",
    "reddit_output = []\n",
    "\n",
    "for post_id in conversedict:\n",
    "    submission = conversedict[post_id][0]\n",
    "    comments = conversedict[post_id][1]\n",
    "    if len(comments) > 1:\n",
    "        print(f'Submission: {submission}')\n",
    "        for comment in comments:\n",
    "            reddit_output.append(comments[comment])\n",
    "            print(f'Comments: {comments[comment]}')\n",
    "        print(35*'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the output of the variable\n",
    "reddit_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.DataFrame(reddit_output, columns = [\"Upvotes\", \"Text\"])\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save original message as file name...\n",
    "reddit_df.to_csv(\"blm_reddit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that you probably will want more data from this API than just submissions and comments with their upvotes! The Reddit API allows access to a lot more metadata â€“ submission dates, \"Flair\" (a way of categorizing data that works differently for each community), and so on. It all depends on the research question you're asking. But in general, when collecting data from an API, it's worthwhile to not cut any corners. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter\n",
    "\n",
    "Twitter works similarly, but you have to fill out more information to get permission to use their API. \n",
    "\n",
    "Here is a nice Tweepy walkthrough: \n",
    "\n",
    "https://realpython.com/twitter-bot-python-tweepy/\n",
    "\n",
    "[The Tweepy docs are also very useful!](http://docs.tweepy.org/en/latest/)\n",
    "\n",
    "1. Visit the Twitter Developer site: https://developer.twitter.com/en and create an account/login\n",
    "2. Navigate to the Developer Portal\n",
    "3. Under Projects & Apps, create a new project (note down the API codes).\n",
    "4. Create a new app within the project and generate access keys (note down the API codes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Authenticate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to reddit! \n",
    "auth = tweepy.OAuthHandler(\"API_KEY\", \"API_SECRET\")\n",
    "auth.set_access_token(\"ACCESS_TOKEN\", \"ACCESS_TOKEN_SECRET\")\n",
    "\n",
    "# What do these arguments do?\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check - did you validate correctly?\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Success!\")\n",
    "except:\n",
    "    print(\"Invalid authentication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweepy methods!\n",
    "# tweepy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe the Internet can provide better explanations?\n",
    "#tweepy.API?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find followers\n",
    "user = api.get_user(screen_name=\"BarackObama\")\n",
    "\n",
    "print(\"User details:\")\n",
    "print(user.name)\n",
    "print(user.description)\n",
    "print(user.location)\n",
    "\n",
    "print(\"Last 20 Followers:\")\n",
    "for follower in user.followers():\n",
    "    print(follower.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the User object for a twitter handle...\n",
    "user = api.get_user(screen_name='BarackObama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty list\n",
    "\n",
    "def tweets(user_name):\n",
    "          \n",
    "    # Authorize yourself\n",
    "    # consumer_key, consumer_secret\n",
    "    auth = tweepy.OAuthHandler(\"API_KEY\", \"API_SECRET\")\n",
    "\n",
    "    # Provide your tokens\n",
    "    # access_key, access_secret\n",
    "    auth.set_access_token(\"ACCESS_TOKEN\", \"ACCESS_TOKEN_SECRET\")\n",
    "\n",
    "    # Define an API instance\n",
    "    api = tweepy.API(auth)\n",
    "  \n",
    "    # Define an empty list to store the tweets\n",
    "    storage = []\n",
    "\n",
    "    # Get 20 tweets\n",
    "    num_tweets = 20\n",
    "    tweets = api.user_timeline(screen_name = user_name)\n",
    "  \n",
    "    # Return user, tweet, date and time, and body\n",
    "    tweet_data = [tweet.text for tweet in tweets]\n",
    "    for i in tweet_data: \n",
    "  \n",
    "        # Append storage\n",
    "        storage.append(i)\n",
    "\n",
    "    # What to return?\n",
    "    return storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_output = tweets(\"BarackObama\")\n",
    "print(twitter_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "twitter_df = pd.DataFrame(twitter_output, columns = [\"Tweet\"])\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.to_csv(\"Obama_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TWEETS = 10\n",
    "\n",
    "blm_tweets = []\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search_tweets, q='#BLM').items(MAX_TWEETS):\n",
    "    blm_tweets.append(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blm_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
